1、MapReduce的shuffle的过程
        Shuffle一开始就是map阶段做输出操作，因此map写入磁盘的过程十分的复杂，更何况map输出时候要对结果进行排序，内存开销是很大的，
            Spill过程：
                map在做输出时候会在内存里开启一个环形内存缓冲区，这个缓冲区专门用来输出的，默认大小是100mb，并且在配置文件里为这个缓冲区设定了一个阀值，默认是0.80（这个大小和阀值都是可以在配置文件里进行配置的），
                同时map还会为输出操作启动一个守护线程，如果缓冲区的内存达到了阀值的80%时候，这个守护线程就会把内容写到磁盘上，这个过程叫spill
                另外的20%内存可以继续写入要写进磁盘的数据，写入磁盘和写入内存操作是互不干扰的，如果缓存区被撑满了，那么map就会阻塞写入内存的操作，让写入磁盘操作完成后再继续执行写入内存操作，
                每次spill操作也就是写入磁盘操作时候就会写一个溢出文件，也就是说在做map输出有几次spill就会产生多少个溢出文件，等map输出全部做完后，map会合并这些输出文件。
            其实Partitioner操作和map阶段的输入分片（Input split）很像，一个Partitioner对应一个reduce作业，如果我们mapreduce操作只有一个reduce操作，那么Partitioner就只有一个，如果我们有多个reduce操作，那么Partitioner对应的就会有多个，
            Partitioner因此就是reduce的输入分片，
            这个程序员可以编程控制，主要是根据实际key和value的值，根据实际业务类型或者为了更好的reduce负载均衡要求进行，这是提高reduce效率的一个关键所在。
            到了reduce阶段就是合并map输出文件了，Partitioner会找到对应的map输出文件，
            然后进行复制操作，复制操作时reduce会开启几个复制线程，这些线程默认个数是5个，程序员也可以在配置文件更改复制线程的个数，
            这个复制过程和map写入磁盘过程类似，也有阀值和内存大小，阀值一样可以在配置文件里配置，而内存大小是直接使用reduce的tasktracker的内存大小，复制时候reduce还会进行排序操作和合并文件操作，这些操作完了就会进行reduce计算了。


2、Kafka有哪几种角色，分别是干什么的？当一个Kafka的bokerid挂掉怎么保证数据的一致性。
    producer
    broker
    consumer
        默认情况下，Kafka的replication数量为1，每个partition都有一个唯一的leader，所有的读写操作都在leader上完成，follower副本批量从leader上pull数据。
    一般情况下partition的数量大于等于broker的数量，并且所有partition的leader均匀分布在broker上。follower上的日志和其leader上的完全一样。
        对于Kafka而言，Kafka存活包含两个条件，
                一是它必须维护与Zookeeper的session(这个通过Zookeeper的heartbeat机制来实现)。
                二是follower必须能够及时将leader的writing复制过来，不能“落后太多”。这里所描述的“落后太多”指follower复制的消息落后于leader后的条数超过预定值，
                    在$KAFKA_HOME/config/server.properties中配置

                    #If a replica falls more than this many messages behind the leader, the leader will remove the follower from ISR and treat it as dead
                    replica.lag.max.messages=4000

                    #If a follower hasn't sent any fetch requests for this window of time, the leader will remove the follower from ISR (in-sync replicas) and treat it as dead
                    replica.lag.time.max.ms=10000
        而Kafka的这种使用“in sync” list的方式
            则很好的均衡了确保数据不丢失以及吞吐率。一条消息只有被 “in sync” list   里的所有follower都从leader复制过去才会被认为已提交。
            leader会track“in sync”的node list。如果一个follower宕机，或者落后太多，leader将把它从”in sync” list中移除。
            follower可以批量的从leader复制数据，这样极大的提高复制性能（批量写磁盘），极大减少了follower与leader的差距（前文有说到，只要follower落后leader不太远，则被认为在“in sync” list里）。
        另外一个很重要的问题是当leader宕机了，怎样在follower中选举出新的leader。
            如果leader不在了，新的leader必须拥有原来的leader commit的所有消息。
            Kafka在Zookeeper中动态维护了一个ISR（in-sync replicas） set，这个set里的所有replica都跟上了leader，只有ISR里的成员才有被选为leader的可能。


        consumer只会从每个partition的leader读数据，而与replicaiton factor无关。同样，consumer吞吐率也与同步复制还是异步复制无关。

3、MapReduce过程中导致数据倾斜怎么解决？碰到的问题是什么？

4、Flume运行机制是什么？里面有哪些组件？每个组件是干什么的？
5、有一个User（全量表）数据是20130101到20140614数据，按当天日期格式分区，查询当天的新增数据。
6、数组A 中有n个元素，数组B中有m个元素，进行排序，保证时间复杂度为O(m+n)（注意：归并排序）
7、redis数据存储类型
8、JVM，GC原理机制以及性能调优

9、多线程，锁在项目中的应用及遇到的问题和解决思路


10、对NIO的理解
11、单例模式手写
12、Hive的分区和join
13、数据倾斜

14、java中hashCode方法与equals方法的用法总结
    要想保证元素不重复，可两个元素是否重复应该依据什么来判断呢？ 这就是Object.equals方法了
        当集合要添加新的元素时，先调用这个元素的hashCode方法，就一下子能定位到它应该放置的物理位置上。
        如果这个位置上没有元素，它就可以直接存储在这个位置上，不用再进行任何比较了；如果这个位置上已经有元素了， 就调用它的equals方法与新元素进行比较，相同的话就不存了，不相同就散列其它的地址。

     Java对于eqauls方法和hashCode方法是这样规定的：
        1、如果两个对象相同，那么它们的hashCode值一定要相同；如果两个对象是相等的，那么它们必须有相同的哈希码。
        2、如果两个对象的hashCode相同，它们并不一定相同（上面说的对象相同指的是用eqauls方法比较。）如果两个对象具有相同的哈希码，他们可能相等，可能不相等。


     hashCode()的返回值和equals()的关系如下：
     •对称性：如果x.equals(y)返回是“true”，那么y.equals(x)也应该返回是“true”。
     •反射性：x.equals(x)必须返回是“true”。
     •类推性：如果x.equals(y)返回是“true”，而且y.equals(z)返回是“true”，那么z.equals(x)也应该返回是“true”。
     •还有一致性：如果x.equals(y)返回是“true”，只要x和y内容一直不变，不管你重复x.equals(y)多少次，返回都是“true”。
     •任何情况下，x.equals(null)，永远返回是“false”；x.equals(和x不同类型的对象)永远返回是“false”。

     hashCode()的返回值和equals()的关系如下：
     •如果x.equals(y)返回“true”，那么x和y的hashCode()必须相等。
     •如果x.equals(y)返回“false”，那么x和y的hashCode()有可能相等，也有可能不等。